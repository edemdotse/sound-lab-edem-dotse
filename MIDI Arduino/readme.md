For my MIDI Arduino project, I borrowed one of the MIDI Arduino kits and hooked it up to FL Studio to create a simple arpeggiator which plays a 15 note sequence in ascending and descending order on a loop whenever the button is pressed, and it stops when the button is released. Each button has a different arpeggio. Blue plays a D flat Major 9, Green plays a G flat 9 and Red plays an F minor 9. This was inspired by the Scaler 2 VST (seen in the performance video) which helps musicians who don't understand music theory to generate interesting
chord progressions and also learn the theory in the process. Full disclosure, this code was written with ChatGPT, based on the MIDI notes example, but I used ChatGPT to learn Arduino notation as well as to explain Wayne's code as well and its own code, so I learned a lot about the Arduino programming language. The documentation of our conversation is over 100 pages long. I asked it to extend the chords to play 15 notes in the same scale, which was the basis for the arpeggio. I tried to get the potentiometer to adjust the speed of the arpeggio sequences, which worked for a bit but then started to glitch out so I abandoned that part. 
The code had a lot of issues with note triggering, so chatGPT built a failsafe while clause tracking the time between each note played in the arpeggio using the millis() function to ensure each note is turned off before the next note plays. It also uses dereferencing and addressing notation to try to account for switch bouncing (?) to keep the button state as pressed constant while the button is triggered. It could not get a perfect arpeggio timing but it got somewhat close. 
The arpeggio itself is a set of if clauses assuming a boolean variable for ascending as true and increasing the note incremently until it reaches the last note in the sequence, then reducing it decrementally while the note is greater than 0.
I gained a better understanding of a potential approach to an arpeggiator, and I feel like I have a better understanding of MIDI Arduino as a language, and the MIDI USB library. However, I feel like there might be a more elegant solution which fixes the bounce issues and gives a smoother arpeggio using some other Arduino libraries. 
I think this approach might help people who don't know how to play instruments create harmonious sounding music with simple triggers. I'm interested in trying to use different sensors to generate sounds for a more embodied performance like in the Imogen Heap performance.
